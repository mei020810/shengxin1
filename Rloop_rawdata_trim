# md5sum -c md5.txt 
#示例：-q 25 --stringency 1 --fastqc --length 35 --paired --trim1 原始reads 先用trim_galore 过滤
# -q 25：质量控制;  --stringency 1：接头序列与读长序列匹配时所需的最小重叠碱基数;  --fastqc：质控报告;  --length 35：长度过滤，读长的长度小于35个碱基，则整条读长都会被丢弃;  --paired：双端模式 --trim1:从每个read的3'端修剪1个碱基
#利用bowtie1比对
#示例：bowtie -a -m 1 --best --strata -p 80 --chunkmbs 200  -X 800 ~/index/Gmax_508_v4.0.bw1  -1 $sample'_R1_val_1.fq.gz'  -2 $sample'_R2_val_2.fq.gz'  -S $sample'_x800.bw1.sam'
# -a : 报告所有可比对结果; -m 1 : 限制每条序列最多1个可比对位置;  --best --strata : 报告最佳比对;  -p 80 : 使用80个CPU核心;  -X 800 : 最大插入片段大小800bp
# https://www.jianshu.com/p/e20a3b73dcd0 比对完用picard 去重复

conda activate study_rna
vim trim_rloop.sh
#!/bin/bash

# 设置最大并发任务数
MAX_JOBS=2
current_jobs=0

for r1_file in *_R1.fastq.gz; do
    r2_file=${r1_file/_R1/_R2}
    sample_name=${r1_file%%_R1.fastq.gz}
    
    # 如果当前任务数达到上限，等待
    while [ $(jobs -r | wc -l) -ge $MAX_JOBS ]; do
        echo "等待空闲资源... 当前运行任务: $(jobs -r | wc -l)"
        sleep 60
    done
    
    echo "启动: $sample_name - $(date)"
    
    # 启动任务
    nohup trim_galore --cores 4 -q 25 --stringency 1 --fastqc --length 35 --paired \
        --three_prime_clip_R1 1 --three_prime_clip_R2 1 \  #代替--trim1
        --output_dir ./trimmed_results \
        $r1_file $r2_file > ${sample_name}_trim.log 2>&1 &

    current_jobs=$((current_jobs + 1))
    echo "进度: $current_jobs 个任务已提交"
    
    sleep 5
done

echo "所有任务提交完成，等待最终完成..."
wait
echo "全部任务完成！时间: $(date)"

chmod u+x trim_rloop.sh
nohup ./trim_rloop.sh &  #tail -f nohup.out 查看任务进程 

cp /mnt/nfs2/stu_fy/hms/Data/Gmax_508_Wm82/Gmax_508_v4.0.fa /data/mshe/rloopData
# 建立bwtie的索引
bowtie-build -f Gmax_508_v4.0.fa ./index/Gmax_508_v4.0.bw1     #bw1
bowtie2-build --threads 10 Gmax_508_v4.0.fa ./index/Gmax_508_v4.0.bw2     #bw2

# 创建解压目录（bowtie1只能用解压后的.fq文件）
mkdir trimmed_results_uncompressed
# 批量解压所有文件
for file in trimmed_results/*.fq.gz; do
    base=$(basename "$file" .gz)
    echo "解压: $file"
    gunzip -c "$file" > "trimmed_results_uncompressed/$base"
done

# 比对
vim bw1_rloop.sh

#!/bin/bash
# 设置最大并发任务数
MAX_JOBS=2
current_jobs=0
INDEX_BASE="/data/mshe/rloopData/index/Gmax_508_v4.0.bw1"

for r1_file in trimmed_results_uncompressed/*_R1_val_1.fq; do
    # 提取样本名（去掉路径和_R1_val_1.fq）
    sample=$(basename "$r1_file" _R1_val_1.fq)
    
    # 检查对应的R2文件是否存在
    r2_file="trimmed_results_uncompressed/${sample}_R2_val_2.fq"
    if [ ! -f "$r2_file" ]; then
        echo "警告: 找不到对应的R2文件 $r2_file，跳过"
        continue
    fi
    
    while [ $(jobs -r | wc -l) -ge $MAX_JOBS ]; do
        echo "等待空闲资源... 当前运行任务: $(jobs -r | wc -l)"
        sleep 60
    done
    echo "启动: $sample - $(date)"

 nohup bowtie -a -m 1 --best --strata -p 10 --chunkmbs 200 -X 800 \
        "$INDEX_BASE" \
        -1 "$r1_file" \
        -2 "$r2_file" \
        -S "/data/mshe/rloopData/sam/${sample}_x800.bw1.sam" > "/data/mshe/rloopData/sam/${sample}_bw1.log" 2>&1 &
    
    current_jobs=$((current_jobs + 1))
    echo "进度: $current_jobs 个任务已提交"
    
    sleep 5
done 
echo "所有任务提交完成，等待最终完成..."
wait
echo "全部任务完成！时间: $(date)"

chmod u+x bw1_rloop.sh
nohup ./bw1_rloop.sh > "bw1_rloop.log" 2>&1 &
# 提取所有样本的比对率进行对比
for log_file in sam/*_bw1.log; do
    sample=$(basename "$log_file" _bw1.log)
    alignment_rate=$(grep "reads with at least one" "$log_file" | awk '{print $10}' | tr -d '()%')
    total_reads=$(grep "reads processed" "$log_file" | awk '{print $4}')
    echo "$sample | 总序列: $total_reads | 比对率: ${alignment_rate}%"
done | sort -t'|' -k5 -nr
# bw1比对率过低，尝试bw2比对
conda activate study_rna
vim bw2_rloop.sh
#!/bin/bash
# 设置最大并发任务数
MAX_JOBS=2
current_jobs=0
INDEX_BASE="/data/mshe/rloopData/index/Gmax_508_v4.0.bw2"

echo "=== 开始Bowtie2比对分析 ==="
echo "开始时间: $(date)"
echo "索引: $INDEX_BASE"
echo "最大并发任务: $MAX_JOBS"

for r1_file in trimmed_results/*_R1_val_1.fq.gz; do
    # 提取样本名（去掉路径和_R1_val_1.fq.gz）
    sample=$(basename "$r1_file" _R1_val_1.fq.gz)
    
    # 检查对应的R2文件是否存在
    r2_file="trimmed_results/${sample}_R2_val_2.fq.gz"
    if [ ! -f "$r2_file" ]; then
        echo "警告: 找不到对应的R2文件 $r2_file，跳过"
        continue
    fi
    
    while [ $(jobs -r | wc -l) -ge $MAX_JOBS ]; do
        echo "等待空闲资源... 当前运行任务: $(jobs -r | wc -l)"
        sleep 60
    done
    echo "启动: $sample - $(date)"

nohup bowtie2 --end-to-end --no-discordant --no-mixed \
        -p 8 \
        -X 800 \
        -x "$INDEX_BASE" \
        -1 "$r1_file" \
        -2 "$r2_file" \
        -S "/data/mshe/rloopData/sam/${sample}_x800.bw2.sam" > "/data/mshe/rloopData/sam/${sample}_bw2.log" 2>&1 &

    current_jobs=$((current_jobs + 1))
    echo "进度: $current_jobs 个任务已提交"
    
    sleep 5
done 
echo "所有任务提交完成，等待最终完成..."
wait

echo "=== 最终统计结果 ==="

for log_file in /data/mshe/rloopData/sam/*_bw2.log; do
    if [ -f "$log_file" ]; then
        sample=$(basename "$log_file" _bw2.log)
        alignment_rate=$(grep "overall alignment rate" "$log_file" | awk '{print $1}' | tr -d '%')
        total_reads=$(grep "reads; of these:" "$log_file" | awk '{print $1}')
        
        if [ -n "$alignment_rate" ] && [ -n "$total_reads" ]; then
            echo "$sample | 总序列: $total_reads | 比对率: ${alignment_rate}%"
        else
            echo "$sample | 统计信息提取失败"
        fi
    fi
done | sort -t'|' -k5 -nr

echo "全部任务完成！时间: $(date)"

chmod u+x bw2_rloop.sh
nohup ./bw2_rloop.sh > "bw2_rloop.log" 2>&1 &    # tail -f bw2_rloop.log



# sam → bam
vim sam_to_bam_picard.sh
#!/bin/bash
MAX_JOBS=2
current_jobs=0
# 创建输出目录
mkdir -p /data/mshe/rloopData/bam
mkdir -p /data/mshe/rloopData/picard
mkdir -p /data/mshe/rloopData/logs

echo "=== 开始批量处理 SAM 文件 ==="
echo "开始时间: $(date)"

for sam_file in sam/*.bw2.sam; do
    # 等待资源
    while [ $(jobs -r | wc -l) -ge $MAX_JOBS ]; do
        echo "等待空闲资源... 当前运行任务: $(jobs -r | wc -l)"
        sleep 60
    done
    
    sample=$(basename "$sam_file" _x800.bw2.sam)
    echo "启动处理: $sample - $(date)"
    
    # 在子shell中运行整个处理流程
    nohup bash -c "
        echo '  - SAM转BAM并排序: $sample'
        samtools sort -@ 8 '$sam_file' -o '/data/mshe/rloopData/bam/${sample}_x800.sorted.bam'

        echo '  - 建立索引: $sample'
        samtools index '/data/mshe/rloopData/bam/${sample}_x800.sorted.bam'

        echo '  - Picard标记重复: $sample'
        picard MarkDuplicates \
            REMOVE_DUPLICATES=true \
            CREATE_INDEX=true \
            MAX_FILE_HANDLES=800 \
            VALIDATION_STRINGENCY=LENIENT \
            I='/data/mshe/rloopData/bam/${sample}_x800.sorted.bam' \
            O='/data/mshe/rloopData/picard/${sample}_picard.bam' \
            M='/data/mshe/rloopData/picard/${sample}_picard_metrics.txt'
        
        echo '  - 完成: $sample'
    " > "/data/mshe/rloopData/logs/${sample}_sam_bam_picard.log" 2>&1 &
    
    current_jobs=$((current_jobs + 1))
    echo "进度: $current_jobs 个任务已提交 - 样本: $sample"
    sleep 10
done 

echo "所有任务提交完成，等待最终完成..."
wait
echo "=== 全部任务完成！ ==="
echo "完成时间: $(date)"
echo "总处理样本数: $current_jobs"

chmod u+x sam_to_bam_picard.sh
nohup ./sam_to_bam_picard.sh > sam_to_bam_picard.log 2>&1 &

# 利用samtools分析比对率
vim samtools_flagstat_analysis.sh
#!/bin/bash
mkdir -p /data/mshe/rloopData/alignment_stats
echo "=== 开始BAM文件统计分析 ==="
echo "开始时间: $(date)"
for bam_file in /data/mshe/rloopData/bam/*.sorted.bam; do
    sample=$(basename "$bam_file" _x800.sorted.bam)
    echo "=== 分析 $sample ==="
samtools flagstat "$bam_file" > "/data/mshe/rloopData/alignment_stats/${sample}_flagstat.txt"
# 提取关键信息
    total_reads=$(grep "in total" "/data/mshe/rloopData/alignment_stats/${sample}_flagstat.txt" | awk '{print $1}')
    mapped_rate=$(grep "mapped" "/data/mshe/rloopData/alignment_stats/${sample}_flagstat.txt" | awk '{print $5}' | head -1)
    properly_paired=$(grep "properly paired" "/data/mshe/rloopData/alignment_stats/${sample}_flagstat.txt" | awk '{print $6}')
    if [ -n "$total_reads" ] && [ -n "$mapped_rate" ]; then
        echo "$sample: 总reads=$total_reads, 比对率=$mapped_rate, 正确配对=$properly_paired"
    else
        echo "$sample: 统计信息提取失败"
    fi
done
echo "=== 分析完成 ==="
echo "结束时间: $(date)"

chmod u+x samtools_flagstat_analysis.sh
nohup ./samtools_flagstat_analysis.sh > samtools_flagstat_analysis.log  2>&1 &
